[build-system]
requires = ["poetry>=1.0"]
build-backend = "poetry.masonry.api"

[tool.poetry]
name = "email_stream_processor"
version = "0.0.1"
description = """
Processing Kafka email events and processing them using Spark Structured Streaming.
"""
authors = [
    "Cathal Mullan <cmullan@proofpoint.com>"
]
license = "Apache-2.0"
readme = "README.md"

[tool.poetry.dependencies]
python = ">=3.6.1, <3.7"
tqdm = "^4.36"
requests = "^2.22"
validators = "^0.14.0"
talon = "^1.4"
faker = "^2.0"
spacy = "^2.2"
pyspark = "^2.4"
python-dotenv = "^0.10.3"
setuptools = "^45.1.0"
pandas = "^1.0.0"
pyarrow = "^0.15.1"
beautifulsoup4 = "^4.8.2"
python-snappy = "^0.5.4"
gcsfs = "^0.6.1"
dataclasses = "^0.7"
matplotlib = "^3.2.1"

[tool.poetry.dev-dependencies]
pre-commit = "1.18.2"
pytest = "5.1.0"
pytest-cov = "2.7.1"
pyspark-stubs = "^2.4"

[tool.poetry.scripts]
download_spacy_model = "email_stream_processor.download.download_spacy_model:main"
download_enron_dataset = "email_stream_processor.download.download_enron_dataset:main"
eml_pipeline = "email_stream_processor.spark_stream.eml_pipeline:main"
vectorize_emails = "email_stream_processor.spark_stream.vectorize_emails:main"

[tool.black]
line-length = 120
target_version = ['py36']

[tool.isort]
line_length = 120
multi_line_output = 3
combine_as_imports = true
include_trailing_comma = true
known_third_party = ["bs4", "dataclasses", "dotenv", "faker", "gcsfs", "numpy", "pandas", "pyarrow", "pyspark", "pytest", "requests", "scipy", "sklearn", "spacy", "talon", "tqdm", "validators"]
